{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION GENERATOR using Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links:\n",
    "Policy Gradient Explanation: http://karpathy.github.io/2016/05/31/rl/ <br>\n",
    "Example of Policy Gradient: https://github.com/keon/policy-gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import TimeDistributed, Dense, Reshape, Flatten, GRU, Input, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from PolicyGradientModel import PolicyGradientModel\n",
    "from RewardCalculator import RewardCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_PARAMETERS = list('XY')\n",
    "ALLOWED_SYMBOLS = ALLOWED_PARAMETERS + list('0123456789+-*/#')\n",
    "NUM_SYMBOLS = len(ALLOWED_SYMBOLS)\n",
    "MAX_LENGTH = 10 # Max length of the output expression\n",
    "CORRECT_EXPRESSION = \"3*X+2*Y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    # Trying to neglect input\n",
    "    input1 = Input(shape=(1,1))\n",
    "    # TODO: Add noise layer to make output vary\n",
    "    x = GRU(32)(input1)\n",
    "    out = Dense(NUM_SYMBOLS, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = []\n",
    "setting.append([0.0,0.6,-0.0,0.05,-0.7]) # Converge to Number + Math Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewardCalculator = RewardCalculator(correctExpression=CORRECT_EXPRESSION,\n",
    "                                    parameters=ALLOWED_PARAMETERS,\n",
    "                                    functionDifferenceRewardWeight=0.0,\n",
    "                                    compilableRewardWeight=0.60, \n",
    "                                    lengthRewardWeight=-0.00,\n",
    "                                    foundMathSymbolWeight=0.05,\n",
    "                                    foundVariableWeight=0.00,\n",
    "                                    rewardOffset=-0.7,\n",
    "                                    usingFile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel()\n",
    "pgModel = PolicyGradientModel(model=model,\n",
    "                              allowedSymbol=ALLOWED_SYMBOLS,\n",
    "                              numSymbol=NUM_SYMBOLS,\n",
    "                              maxLength=MAX_LENGTH,\n",
    "                              rewardCalculator=rewardCalculator,\n",
    "                              learningRate=0.0001,\n",
    "                              fileName=\"Model1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgModel.loadWeight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 24.2600702286\tExample Output: XX5660Y11/\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 1\tLoss: 24.3220811844\tExample Output: 81+\tExample Reward:  -1\n",
      "Epoch: 2\tLoss: 24.3805141449\tExample Output: *Y04643726\tExample Reward:  -1\n",
      "Epoch: 3\tLoss: 24.417432785\tExample Output: \tExample Reward:  -1\n",
      "Epoch: 4\tLoss: 24.4529138565\tExample Output: Y8+4Y/4*74\tExample Reward:  -1\n",
      "Epoch: 5\tLoss: 24.4757192612\tExample Output: 7*89199Y+2\tExample Reward:  -1\n",
      "Epoch: 6\tLoss: 24.4907264709\tExample Output: \tExample Reward:  -1\n",
      "Epoch: 7\tLoss: 24.507711792\tExample Output: 8\tExample Reward:  -0.1\n",
      "Epoch: 8\tLoss: 24.5395874023\tExample Output: \tExample Reward:  -1\n",
      "Epoch: 9\tLoss: 24.5744539261\tExample Output: \tExample Reward:  -1\n",
      "Epoch: 10\tLoss: 24.6164491653\tExample Output: 926Y+8/X9/\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 11\tLoss: 24.6509269714\tExample Output: 3+/60XX312\tExample Reward:  -1\n",
      "Epoch: 12\tLoss: 24.6674991608\tExample Output: 0*9+6\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 13\tLoss: 24.6913784027\tExample Output: *82/2\tExample Reward:  -1\n",
      "Epoch: 14\tLoss: 24.7286985397\tExample Output: +9-X\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 15\tLoss: 24.7617401123\tExample Output: +Y-X3/6135\tExample Reward:  -1\n",
      "Epoch: 16\tLoss: 24.788428688\tExample Output: 086820678+\tExample Reward:  -1\n",
      "Epoch: 17\tLoss: 24.8116264343\tExample Output: 0//43Y65+8\tExample Reward:  -1\n",
      "Epoch: 18\tLoss: 24.8363201141\tExample Output: 6/*38-13/3\tExample Reward:  -1\n",
      "Epoch: 19\tLoss: 24.8556900024\tExample Output: -X2734+4\tExample Reward:  -1\n",
      "Epoch: 20\tLoss: 24.8657072067\tExample Output: 6247\tExample Reward:  -0.1\n",
      "Saving Weight\n",
      "Epoch: 21\tLoss: 24.8802722931\tExample Output: X6864\tExample Reward:  -1\n",
      "Epoch: 22\tLoss: 24.9060405731\tExample Output: 5813X9-//5\tExample Reward:  -1\n",
      "Epoch: 23\tLoss: 24.9353832245\tExample Output: Y79*71/-55\tExample Reward:  -1\n",
      "Epoch: 24\tLoss: 24.9617961884\tExample Output: X-480/0/8*\tExample Reward:  -1\n",
      "Epoch: 25\tLoss: 24.9678567886\tExample Output: X81-X7Y6+9\tExample Reward:  -1\n",
      "Epoch: 26\tLoss: 24.9903762817\tExample Output: 6904/6X*\tExample Reward:  -1\n",
      "Epoch: 27\tLoss: 25.013482666\tExample Output: 26/60\tExample Reward:  -0.05\n",
      "Epoch: 28\tLoss: 25.028395462\tExample Output: 6+Y7X7XX19\tExample Reward:  -1\n",
      "Epoch: 29\tLoss: 25.0643253326\tExample Output: 59040X00*5\tExample Reward:  -1\n",
      "Epoch: 30\tLoss: 25.1126001358\tExample Output: 97927\tExample Reward:  -0.1\n",
      "Saving Weight\n",
      "Epoch: 31\tLoss: 25.1465795517\tExample Output: 6\tExample Reward:  -0.1\n",
      "Epoch: 32\tLoss: 25.1903144836\tExample Output: 41X+3-71\tExample Reward:  -1\n",
      "Epoch: 33\tLoss: 25.2123260498\tExample Output: +Y9*2/3X*0\tExample Reward:  -1\n",
      "Epoch: 34\tLoss: 25.223188591\tExample Output: 5-11*7/438\tExample Reward:  0.05\n",
      "Epoch: 35\tLoss: 25.2396245956\tExample Output: 76*Y5/\tExample Reward:  -1\n",
      "Epoch: 36\tLoss: 25.2692403793\tExample Output: 945960//\tExample Reward:  -1\n",
      "Epoch: 37\tLoss: 25.2852344513\tExample Output: 0-4*929962\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 38\tLoss: 25.3136306763\tExample Output: 68X6519258\tExample Reward:  -1\n",
      "Epoch: 39\tLoss: 25.3226062775\tExample Output: /8+X\tExample Reward:  -1\n",
      "Epoch: 40\tLoss: 25.3250696182\tExample Output: 8477-8\tExample Reward:  -0.05\n",
      "Saving Weight\n",
      "Epoch: 41\tLoss: 25.3309307098\tExample Output: *853132423\tExample Reward:  -1\n",
      "Epoch: 42\tLoss: 25.3315862656\tExample Output: X065627687\tExample Reward:  -1\n",
      "Epoch: 43\tLoss: 25.3245605469\tExample Output: 52*30-7243\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 44\tLoss: 25.3271066666\tExample Output: 70\tExample Reward:  -0.1\n",
      "Epoch: 45\tLoss: 25.3552873611\tExample Output: 8342**7171\tExample Reward:  -1\n",
      "Epoch: 46\tLoss: 25.4014547348\tExample Output: 4*0**31817\tExample Reward:  -1\n",
      "Epoch: 47\tLoss: 25.4431497574\tExample Output: 6/0/5931+9\tExample Reward:  -1\n",
      "Epoch: 48\tLoss: 25.4580541611\tExample Output: +*8/Y61+26\tExample Reward:  -1\n",
      "Epoch: 49\tLoss: 25.4806230545\tExample Output: +67\tExample Reward:  -0.05\n",
      "Epoch: 50\tLoss: 25.5177713394\tExample Output: 9//-1Y05/4\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 51\tLoss: 25.5356782913\tExample Output: 6X/78*14X9\tExample Reward:  -1\n",
      "Epoch: 52\tLoss: 25.5427642822\tExample Output: \tExample Reward:  -1\n",
      "Epoch: 53\tLoss: 25.5768743515\tExample Output: 7/82/3-352\tExample Reward:  0.05\n",
      "Epoch: 54\tLoss: 25.6004369736\tExample Output: 163637*550\tExample Reward:  -0.05\n",
      "Epoch: 55\tLoss: 25.6064157486\tExample Output: 29X80+6\tExample Reward:  -1\n",
      "Epoch: 56\tLoss: 25.6273862839\tExample Output: \tExample Reward:  -1\n",
      "Epoch: 57\tLoss: 25.7004486084\tExample Output: /5/X1YY-Y0\tExample Reward:  -1\n",
      "Epoch: 58\tLoss: 25.7462551117\tExample Output: 6*73*X\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 59\tLoss: 25.7612306595\tExample Output: +\tExample Reward:  -1\n",
      "Epoch: 60\tLoss: 25.7793413162\tExample Output: 9Y8\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 61\tLoss: 25.801458931\tExample Output: 89+*5*\tExample Reward:  -1\n",
      "Epoch: 62\tLoss: 25.866179657\tExample Output: 039038X089\tExample Reward:  -1\n",
      "Epoch: 63\tLoss: 25.912966156\tExample Output: /608+91+10\tExample Reward:  -1\n",
      "Epoch: 64\tLoss: 25.9246339798\tExample Output: X3455*430X\tExample Reward:  -1\n",
      "Epoch: 65\tLoss: 25.9353521347\tExample Output: 8777X3913Y\tExample Reward:  -1\n",
      "Epoch: 66\tLoss: 25.9442079544\tExample Output: -Y078280/6\tExample Reward:  -1\n",
      "Epoch: 67\tLoss: 25.9808485031\tExample Output: 09/6Y8331/\tExample Reward:  -1\n",
      "Epoch: 68\tLoss: 26.003424263\tExample Output: /49++Y4/78\tExample Reward:  -1\n",
      "Epoch: 69\tLoss: 26.0161506653\tExample Output: 608--5//27\tExample Reward:  0.1\n",
      "Epoch: 70\tLoss: 26.0116233826\tExample Output: 54/8Y0-**7\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 71\tLoss: 26.0050210953\tExample Output: /-X\tExample Reward:  -1\n",
      "Epoch: 72\tLoss: 26.0103017807\tExample Output: 1/963753+X\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 73\tLoss: 26.023081398\tExample Output: 672X08\tExample Reward:  -1\n",
      "Epoch: 74\tLoss: 26.0576507568\tExample Output: 3-9034900Y\tExample Reward:  -1\n",
      "Epoch: 75\tLoss: 26.1078409195\tExample Output: 52652*9Y9*\tExample Reward:  -1\n",
      "Epoch: 76\tLoss: 26.1335926056\tExample Output: 25826060\tExample Reward:  -0.1\n",
      "Epoch: 77\tLoss: 26.1488872528\tExample Output: 3+---/92+X\tExample Reward:  -0.9999999999999998\n",
      "Epoch: 78\tLoss: 26.1544075012\tExample Output: 915067X5Y8\tExample Reward:  -1\n",
      "Epoch: 79\tLoss: 26.1553403854\tExample Output: Y/640-82-9\tExample Reward:  0.05\n",
      "Epoch: 80\tLoss: 26.1577287674\tExample Output: 04911-97Y/\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 81\tLoss: 26.1576850891\tExample Output: /3Y/*/-3/7\tExample Reward:  -0.9999999999999998\n",
      "Epoch: 82\tLoss: 26.154309845\tExample Output: 3834464039\tExample Reward:  -0.1\n",
      "Epoch: 83\tLoss: 26.1558322906\tExample Output: 7Y-3X2+149\tExample Reward:  -1\n",
      "Epoch: 84\tLoss: 26.1556346893\tExample Output: 5*0X019861\tExample Reward:  -0.05\n",
      "Epoch: 85\tLoss: 26.1645580292\tExample Output: 8/0628\tExample Reward:  -1\n",
      "Epoch: 86\tLoss: 26.1845016479\tExample Output: 667\tExample Reward:  -0.1\n",
      "Epoch: 87\tLoss: 26.1967382431\tExample Output: 1375992975\tExample Reward:  -0.1\n",
      "Epoch: 88\tLoss: 26.1949220657\tExample Output: Y1//-X/72Y\tExample Reward:  -1\n",
      "Epoch: 89\tLoss: 26.1833667755\tExample Output: Y1802611YY\tExample Reward:  -1\n",
      "Epoch: 90\tLoss: 26.1719509125\tExample Output: *1-2\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 91\tLoss: 26.1949811935\tExample Output: /8/*2/*130\tExample Reward:  -1\n",
      "Epoch: 92\tLoss: 26.2440881729\tExample Output: 4\tExample Reward:  -0.1\n",
      "Epoch: 93\tLoss: 26.2686223984\tExample Output: 573916-387\tExample Reward:  -0.05\n",
      "Epoch: 94\tLoss: 26.2729024887\tExample Output: 3198X14Y3Y\tExample Reward:  -1\n",
      "Epoch: 95\tLoss: 26.2769994736\tExample Output: /81910\tExample Reward:  -1\n",
      "Epoch: 96\tLoss: 26.2854190826\tExample Output: /0/26-51*8\tExample Reward:  -1\n",
      "Epoch: 97\tLoss: 26.2836870193\tExample Output: X/-82-45-2\tExample Reward:  0.1\n",
      "Epoch: 98\tLoss: 26.2741802216\tExample Output: X34866+8XX\tExample Reward:  -1\n",
      "Epoch: 99\tLoss: 26.2831739426\tExample Output: *64-/X1\tExample Reward:  -1\n",
      "Epoch: 100\tLoss: 26.3882429123\tExample Output: /800XY5138\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 101\tLoss: 26.4497520447\tExample Output: 1/7-4-8164\tExample Reward:  0.05\n",
      "Epoch: 102\tLoss: 26.4713495255\tExample Output: +0787Y*338\tExample Reward:  -1\n",
      "Epoch: 103\tLoss: 26.4769445419\tExample Output: YX0+/82103\tExample Reward:  -1\n",
      "Epoch: 104\tLoss: 26.518686676\tExample Output: 36796180Y8\tExample Reward:  -1\n",
      "Epoch: 105\tLoss: 26.5465284348\tExample Output: 734YX-9014\tExample Reward:  -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106\tLoss: 26.6040924072\tExample Output: 339X05*786\tExample Reward:  -1\n",
      "Epoch: 107\tLoss: 26.6745632172\tExample Output: 0645*43*70\tExample Reward:  -1\n",
      "Epoch: 108\tLoss: 26.7210302353\tExample Output: 482XX0/994\tExample Reward:  -1\n",
      "Epoch: 109\tLoss: 26.7357982635\tExample Output: 2+1-0230+X\tExample Reward:  -1\n",
      "Epoch: 110\tLoss: 26.7651390076\tExample Output: -\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 111\tLoss: 26.8303514481\tExample Output: 8682338+98\tExample Reward:  -0.05\n",
      "Epoch: 112\tLoss: 26.8614048004\tExample Output: 4+82-Y1733\tExample Reward:  -1\n",
      "Epoch: 113\tLoss: 26.930431366\tExample Output: ++*83--643\tExample Reward:  -1\n",
      "Epoch: 114\tLoss: 26.9592653275\tExample Output: 91973-9785\tExample Reward:  -0.05\n",
      "Epoch: 115\tLoss: 26.9680830002\tExample Output: 4666Y721-2\tExample Reward:  -1\n",
      "Epoch: 116\tLoss: 26.9877897263\tExample Output: 08824Y1453\tExample Reward:  -1\n",
      "Epoch: 117\tLoss: 27.0121234894\tExample Output: -*/894-411\tExample Reward:  -1\n",
      "Epoch: 118\tLoss: 27.0353897095\tExample Output: 34/*7YY116\tExample Reward:  -1\n",
      "Epoch: 119\tLoss: 27.0190418243\tExample Output: 5965X65074\tExample Reward:  -1\n",
      "Epoch: 120\tLoss: 27.0117288589\tExample Output: 634*36Y0-3\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 121\tLoss: 27.0069831848\tExample Output: 61/1/++8X*\tExample Reward:  -1\n",
      "Epoch: 122\tLoss: 26.9901229858\tExample Output: 107-+-66/7\tExample Reward:  0.1\n",
      "Epoch: 123\tLoss: 26.9697385788\tExample Output: Y09816-83*\tExample Reward:  -1\n",
      "Epoch: 124\tLoss: 26.9672870636\tExample Output: 38*-99X294\tExample Reward:  -1\n",
      "Epoch: 125\tLoss: 26.9747695923\tExample Output: +66-+Y6X2Y\tExample Reward:  -1\n",
      "Epoch: 126\tLoss: 27.0319677353\tExample Output: 44/43854-2\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 127\tLoss: 27.056489563\tExample Output: 6Y083176Y6\tExample Reward:  -1\n",
      "Epoch: 128\tLoss: 27.0584407806\tExample Output: 360-3-/6+7\tExample Reward:  -1\n",
      "Epoch: 129\tLoss: 27.0449054718\tExample Output: 6Y/+22*594\tExample Reward:  -1\n",
      "Epoch: 130\tLoss: 27.0110746384\tExample Output: +/5990355-\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 131\tLoss: 26.959932518\tExample Output: -*0961+849\tExample Reward:  -1\n",
      "Epoch: 132\tLoss: 26.9256248474\tExample Output: +250975878\tExample Reward:  -0.05\n",
      "Epoch: 133\tLoss: 26.9207363129\tExample Output: 9-54-+-36*\tExample Reward:  -1\n",
      "Epoch: 134\tLoss: 26.9133127213\tExample Output: /-05944X75\tExample Reward:  -1\n",
      "Epoch: 135\tLoss: 26.8988368988\tExample Output: -5098YX--9\tExample Reward:  -1\n",
      "Epoch: 136\tLoss: 26.8773378372\tExample Output: /Y19893086\tExample Reward:  -1\n",
      "Epoch: 137\tLoss: 26.8433322906\tExample Output: -12+/-/22X\tExample Reward:  -1\n",
      "Epoch: 138\tLoss: 26.799785614\tExample Output: +104*6X033\tExample Reward:  -1\n",
      "Epoch: 139\tLoss: 26.8139120102\tExample Output: /-704X5*43\tExample Reward:  -1\n",
      "Epoch: 140\tLoss: 26.8180400848\tExample Output: 2617025490\tExample Reward:  -0.1\n",
      "Saving Weight\n",
      "Epoch: 141\tLoss: 26.7930372238\tExample Output: 249Y*/5253\tExample Reward:  -1\n",
      "Epoch: 142\tLoss: 26.7691318512\tExample Output: 325+5267*-\tExample Reward:  -1\n",
      "Epoch: 143\tLoss: 26.7602287292\tExample Output: 022*4+8-91\tExample Reward:  -1\n",
      "Epoch: 144\tLoss: 26.7631092072\tExample Output: -737841X66\tExample Reward:  -1\n",
      "Epoch: 145\tLoss: 26.7682949066\tExample Output: X1112/41*3\tExample Reward:  -1\n",
      "Epoch: 146\tLoss: 26.769527626\tExample Output: 233-/3X4*1\tExample Reward:  -1\n",
      "Epoch: 147\tLoss: 26.7577842712\tExample Output: 9282/X-+/1\tExample Reward:  -1\n",
      "Epoch: 148\tLoss: 26.7330478668\tExample Output: /06+794020\tExample Reward:  -1\n",
      "Epoch: 149\tLoss: 26.6793584824\tExample Output: 9*689XX427\tExample Reward:  -1\n",
      "Epoch: 150\tLoss: 26.6211624146\tExample Output: 464/Y+0/37\tExample Reward:  0.05\n",
      "Saving Weight\n",
      "Epoch: 151\tLoss: 26.5933681488\tExample Output: 08XYY0X214\tExample Reward:  -1\n",
      "Epoch: 152\tLoss: 26.5531663895\tExample Output: 9/4X23-+62\tExample Reward:  -1\n",
      "Epoch: 153\tLoss: 26.4910734177\tExample Output: +537268277\tExample Reward:  -0.05\n",
      "Epoch: 154\tLoss: 26.4338914871\tExample Output: Y799929541\tExample Reward:  -1\n",
      "Epoch: 155\tLoss: 26.374728775\tExample Output: 01/96135+8\tExample Reward:  -1\n",
      "Epoch: 156\tLoss: 26.294320488\tExample Output: 13/3355/26\tExample Reward:  2.77555756156e-17\n",
      "Epoch: 157\tLoss: 26.2439849854\tExample Output: 3486/0/21-\tExample Reward:  -1\n",
      "Epoch: 158\tLoss: 26.2185939789\tExample Output: 333702-37/\tExample Reward:  -1\n",
      "Epoch: 159\tLoss: 26.2082561493\tExample Output: 9424X3099X\tExample Reward:  -1\n",
      "Epoch: 160\tLoss: 26.1870763779\tExample Output: 89/5478992\tExample Reward:  -0.05\n",
      "Saving Weight\n",
      "Epoch: 161\tLoss: 26.1546726227\tExample Output: +3438-177/\tExample Reward:  -1\n",
      "Epoch: 162\tLoss: 26.1155359268\tExample Output: +76405+72/\tExample Reward:  -1\n",
      "Epoch: 163\tLoss: 26.0817274094\tExample Output: X9-30326/6\tExample Reward:  -1\n",
      "Epoch: 164\tLoss: 26.0405105591\tExample Output: 7Y919+0708\tExample Reward:  -1\n",
      "Epoch: 165\tLoss: 25.9676326752\tExample Output: X8207/5154\tExample Reward:  -1\n",
      "Epoch: 166\tLoss: 25.8926715851\tExample Output: 4*580+8Y+9\tExample Reward:  -1\n",
      "Epoch: 167\tLoss: 25.8491704941\tExample Output: 47-584+Y33\tExample Reward:  -1\n",
      "Epoch: 168\tLoss: 25.819817543\tExample Output: *7-45-4+52\tExample Reward:  -1\n",
      "Epoch: 169\tLoss: 25.7782039642\tExample Output: 54697-5X16\tExample Reward:  -1\n",
      "Epoch: 170\tLoss: 25.7455659866\tExample Output: 16966X527*\tExample Reward:  -1\n",
      "Saving Weight\n",
      "Epoch: 171\tLoss: 25.7441520691\tExample Output: +73238Y/23\tExample Reward:  -1\n",
      "Epoch: 172\tLoss: 25.7325725555\tExample Output: 8457691828\tExample Reward:  -0.1\n",
      "Epoch: 173\tLoss: 25.7041418076\tExample Output: 58+7142665\tExample Reward:  -0.05\n",
      "Epoch: 174\tLoss: 25.7002155304\tExample Output: 6302739*17\tExample Reward:  -0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c8e0472c77ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpgModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/function-generator/PolicyGradientModel.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input, numIterationPerEpoch, numEpoch, numEpochToSaveWeight)\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0moutputAlphabet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallowedSymbol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardCalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalReward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputAlphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/function-generator/RewardCalculator.py\u001b[0m in \u001b[0;36mcalReward\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReward\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcompilableReward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdifferenceReward\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calCompileAndDifferenceReward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mlengthReward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calLengthReward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfoundSymbolReward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calFoundSymbolReward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/function-generator/RewardCalculator.py\u001b[0m in \u001b[0;36m__calCompileAndDifferenceReward\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0;31m# TODO Add using file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calDifferenceWithEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapEach\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapEach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/function-generator/RewardCalculator.py\u001b[0m in \u001b[0;36m__calDifferenceWithEval\u001b[0;34m(self, expression, X, Y)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0moutputVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mebsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/function-generator/RewardCalculator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pgModel.train(input=np.ones((1,1,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
